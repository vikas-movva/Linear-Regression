{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from warnings import warn\n",
    "\n",
    "def linear_regression(x, y, learning_rate=0.0000001, epsilon=0.9) -> np.array:\n",
    "    \"\"\"Linear regression algorithm utilizing gradient decent\n",
    "\n",
    "    Args:\n",
    "        x (numpy.array): Array containing x values from dataset\n",
    "        y (numpy.array): Array containing y valiues from dataset\n",
    "        learning_rate (float, optional): learning rate value represented by alpha. Defaults to 0.0000001.\n",
    "        epsilon (float, optional): error threshold to check for convergence. Defaults to 0.9.\n",
    "\n",
    "    Returns:\n",
    "         np.array: weights for linear regression\n",
    "    \"\"\"\n",
    "    \n",
    "    #insert column for y intercept\n",
    "    regr = np.c_[x, np.ones(len(x))]\n",
    "    \n",
    "    #weights\n",
    "    weights = np.ones(regr.shape[1])\n",
    "    \n",
    "    #gradient descent\n",
    "    norm = 1\n",
    "    while(norm > epsilon):\n",
    "        # calculate partial derivitive\n",
    "        prediction_y = regr @ weights.T\n",
    "        part_deriv = regr.T @ (y - prediction_y)\n",
    "        # calculate normal\n",
    "        norm = np.sum(np.sqrt(np.square(part_deriv)))\n",
    "        # adjust weights based on gradient\n",
    "        weights = weights.T + (learning_rate * part_deriv)\n",
    "        if (np.isnan(norm)):\n",
    "          warn('diverged')\n",
    "\n",
    "          \n",
    "    return weights\n",
    "def mean_squared_error(y, predection_y) -> float:\n",
    "    \"\"\"Get mean squared error\n",
    "\n",
    "    Args:\n",
    "        y (np.array): Values for y\n",
    "        predection_y (np.array): Predicted values for y\n",
    "\n",
    "    Returns:\n",
    "        float: mean squared error\n",
    "    \"\"\"\n",
    "    \n",
    "    #sum of (y_n - pred_y_n) divided by num of y\n",
    "    error = np.sum(np.square(y - predection_y))/float(len(y))\n",
    "    \n",
    "    return error\n",
    "    \n",
    "def predict_y(x:np.array, weights:np.array) -> np.array:\n",
    "    \"\"\"Predict y value\n",
    "\n",
    "    Args:\n",
    "        x (np.array): independant variables\n",
    "        weights (np.array): linear regression weights\n",
    "\n",
    "    Returns:\n",
    "        np.array: predicted values\n",
    "    \"\"\"\n",
    "  # y =       m      *    x          +     b\n",
    "    y = weights[:-1] @ np.array(x).T + weights[-1]\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from file\n",
    "data = pd.read_csv(\"Real estate.csv\")\n",
    "# drop first column which is not usefull \n",
    "data = data.drop(\"No\",axis=1)\n",
    "# show data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataframe to numpy array\n",
    "data = data.to_numpy()\n",
    "#check dimentions of array\n",
    "data.shape\n",
    "# add all but last column to array - independent variables (x)\n",
    "x = data[:, :-1]\n",
    "x.shape\n",
    "# add last column to array - dependent variable (y)\n",
    "y = data[:, -1]\n",
    "y.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('MachineLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "087e8b641f2d1431bd9bc95a919f1a7b9add817acfe363050e84d7c383fe80fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
